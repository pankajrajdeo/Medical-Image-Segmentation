# -*- coding: utf-8 -*-
"""Segmentation01_Swin-tiny

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dwhxdYEGMoGHpG4N46eeYNgAfgnsCcZ1
"""

import os
import torch
import torch.nn as nn
import torch.nn.functional as F
import timm
from google.colab import drive
import matplotlib.pyplot as plt
import numpy as np


# Mount Google Drive
drive.mount('/content/drive')
class LungSegmentationModel(nn.Module):
    def __init__(self, num_classes=2):
        super(LungSegmentationModel, self).__init__()

        # Load Swin Transformer Tiny as the backbone
        self.backbone = timm.create_model('swin_tiny_patch4_window7_224', pretrained=True, num_classes=0, in_chans=3)

        # Replace the last layer to output num_classes channels
        self.last_conv = nn.Conv2d(768, num_classes, kernel_size=1)

    def forward(self, x):
        # Pass input through the backbone
        x = self.backbone(x)

        # Add an additional dimension to the tensor
        x = x.unsqueeze(2).unsqueeze(3)

        # Output segmentation mask
        x = self.last_conv(x)

        # Upsample the output to the same size as the input image
        x = F.interpolate(x, size=(224, 224), mode='bilinear', align_corners=False)

        return x




model = LungSegmentationModel(num_classes=2).cuda()

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

from PIL import Image
from torch.utils.data import Dataset, DataLoader
from torchvision.transforms import Compose, Resize, ToTensor

class LungDataset(Dataset):
    def __init__(self, img_folder, label_folder, transform=None):
        self.img_folder = img_folder
        self.label_folder = label_folder
        self.transform = transform
        self.img_names = os.listdir(img_folder)

    def __len__(self):
        return len(self.img_names)

    def __getitem__(self, idx):
        img_id = self.img_names[idx]
        img_path = os.path.join(self.img_folder, self.img_names[idx])
        label_path = os.path.join(self.label_folder, self.img_names[idx])
        
        img = Image.open(img_path).convert('RGB')
        label = Image.open(label_path).convert('L')

        if self.transform:
            img = self.transform(img)
       
        # Resize label to the same size as the input image without interpolation
        label = np.array(label.resize((224, 224), Image.NEAREST), dtype=np.int64)
        
        # Check input tensor values
        if torch.any(img > 1.0) or torch.any(img < 0.0):
            raise ValueError("Input tensor values should be between 0 and 1.")
        
        return img, label, img_id




transform = Compose([
    Resize((224, 224)),
    ToTensor()
])


train_dataset = LungDataset('/content/drive/My Drive/Liang/Segmentation01_RGB/train/org', '/content/drive/My Drive/Liang/Segmentation01_RGB/train/label', transform=transform)
test_dataset = LungDataset('/content/drive/My Drive/Liang/Segmentation01_RGB/test/org', '/content/drive/My Drive/Liang/Segmentation01_RGB/test/label', transform=transform)

train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=2, shuffle=True)




train_losses = []
test_losses = []

# Training loop
num_epochs = 10



for epoch in range(num_epochs):
  train_loss = 0.0
  for i, (images, labels, _) in enumerate(train_loader):
    # Move images and labels to GPU
    images = images.cuda()
    labels = labels.cuda()

    # Zero out gradients
    optimizer.zero_grad()

    # Forward pass
    outputs = model(images)

    # Compute loss
    loss = criterion(outputs, labels.long())

    # Backward pass and optimization step
    loss.backward()
    optimizer.step()

    train_loss += loss.item() * images.size(0)  # Multiply by batch size

    # Print loss every 10 batches
    if i % 10 == 0:
        print(f"Epoch {epoch+1}/{num_epochs}, Batch {i+1}/{len(train_loader)}, Loss: {loss.item()}")
        train_loss /= len(train_dataset)
        train_losses.append(train_loss)
        print(f"Epoch {epoch+1}/{num_epochs}, Training Loss: {train_loss}")



from sklearn.metrics import confusion_matrix
import numpy as np

def display_predictions(images, labels, outputs, img_ids, iou, iou_threshold):
    for idx in range(images.shape[0]):
        fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))
        
        # Original image
        ax1.imshow(images[idx].permute(1, 2, 0).numpy())
        ax1.set_title(f"Original Image (ID: {img_ids[idx]})")
        
        # Ground truth
        ax2.imshow(labels[idx].numpy(), cmap="gray")
        ax2.set_title("Ground Truth")
        
        # Predicted mask
        ax3.imshow(outputs[idx].numpy(), cmap="gray")
        
        # Print correct or incorrect prediction
        if iou[idx] > iou_threshold:
            ax3.set_title("Correct Prediction")
            print(f"Correct Prediction for Image ID: {img_ids[idx]}")
        else:
            ax3.set_title("Incorrect Prediction")
            print(f"Incorrect Prediction for Image ID: {img_ids[idx]}")
        
        plt.show()


# IoU function
def iou_score(outputs, labels):
    intersection = np.logical_and(outputs, labels)
    union = np.logical_or(outputs, labels)
    iou = np.sum(intersection) / np.sum(union)
    return iou

# Dice Coefficient function
def dice_coefficient(outputs, labels):
    intersection = np.logical_and(outputs, labels)
    dice = 2 * np.sum(intersection) / (np.sum(outputs) + np.sum(labels))
    return dice

# Pixel Accuracy function
def pixel_accuracy(outputs, labels):
    pixel_acc = np.sum(outputs == labels) / np.prod(outputs.shape)
    return pixel_acc

# Evaluate the model on the test set
model.eval()
iou_threshold = 0.8  # Set the IoU threshold

with torch.no_grad():
    iou_scores = []
    dice_scores = []
    pixel_accs = []

    for images, labels, img_ids in test_loader:
        # Move images and labels to GPU
        images = images.cuda()
        labels = labels.cuda()

        # Forward pass
        model = model.to(images.device)
        outputs = model(images)


        # Convert output to binary mask
        outputs = torch.argmax(outputs, dim=1)
        outputs = outputs.cpu().numpy()

        # Calculate IoU, Dice Coefficient, and Pixel Accuracy
        labels = labels.cpu().numpy()
        iou = [iou_score(outputs[idx], labels[idx]) for idx in range(outputs.shape[0])]
        dice = dice_coefficient(outputs, labels)
        pixel_acc = pixel_accuracy(outputs, labels)

        # Display predictions for both correct and incorrect predictions
        display_predictions(images.cpu(), torch.from_numpy(labels), torch.from_numpy(outputs), img_ids, iou, iou_threshold)

        # Append scores to lists
        iou_scores.extend(iou)
        dice_scores.append(dice)
        pixel_accs.append(pixel_acc)

    # Print average scores
    print('Average IoU: {:.4f}'.format(np.mean(iou_scores)))
    print('Average Dice Coefficient: {:.4f}'.format(np.mean(dice_scores)))
    print('Average Pixel Accuracy: {:.4f}'.format(np.mean(pixel_accs)))



    # Evaluate on test set after each epoch
    model.eval()
    with torch.no_grad():
        test_loss = 0
        for images, labels, _ in test_loader:
            # Move images and labels to GPU
            images = images.cuda()
            labels = labels.cuda()

            # Forward pass
            outputs = model(images)

            # Compute loss
            test_loss += criterion(outputs, labels.long()).item()

        test_loss /= len(test_loader)
        print(f"Epoch {epoch+1}/{num_epochs}, Test Loss: {test_loss}")
        test_loss /= len(test_dataset)
        test_losses.append(test_loss)
        print(f"Epoch {epoch+1}/{num_epochs}, Test Loss: {test_loss}")

    model.train()